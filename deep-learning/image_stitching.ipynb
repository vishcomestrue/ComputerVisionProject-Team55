{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning based Image Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homographic Neural Network - Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class HomographyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HomographyNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(6, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 8)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Homography from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class RealHomographyDataset(Dataset):\n",
    "    def __init__(self, img1_path, img2_path, homography_matrix, patch_size=128, num_samples=500):\n",
    "        self.img1 = cv2.resize(cv2.imread(img1_path), (320, 240))\n",
    "        self.img2 = cv2.resize(cv2.imread(img2_path), (320, 240))\n",
    "        self.H = homography_matrix\n",
    "        self.patch_size = patch_size\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        h, w, _ = self.img1.shape\n",
    "        ps = self.patch_size\n",
    "        x = random.randint(0, w - ps - 1)\n",
    "        y = random.randint(0, h - ps - 1)\n",
    "\n",
    "        pts1 = np.array([[x, y], [x+ps, y], [x+ps, y+ps], [x, y+ps]], dtype=np.float32).reshape(-1, 1, 2)\n",
    "        pts2 = cv2.perspectiveTransform(pts1, self.H)\n",
    "\n",
    "        patch_a = self.img1[y:y+ps, x:x+ps].copy()\n",
    "        H_inv = np.linalg.inv(self.H)\n",
    "        warped_img2 = cv2.warpPerspective(self.img2, H_inv, (w, h))\n",
    "        patch_b = warped_img2[y:y+ps, x:x+ps].copy()\n",
    "\n",
    "        pair = np.concatenate([patch_a, patch_b], axis=2).transpose(2, 0, 1).astype(np.float32) / 255.0\n",
    "        label = (pts2.reshape(-1, 2) - pts1.reshape(-1, 2)).reshape(-1).astype(np.float32)\n",
    "\n",
    "        return torch.tensor(pair), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Homography from keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_homography(img1_path, img2_path):\n",
    "    img1 = cv2.resize(cv2.imread(img1_path), (320, 240))\n",
    "    img2 = cv2.resize(cv2.imread(img2_path), (320, 240))\n",
    "    orb = cv2.ORB_create(5000)\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataset):\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.MSELoss()\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(50):\n",
    "        total_loss = 0\n",
    "        for img_pair, labels in loader:\n",
    "            img_pair, labels = img_pair.cuda(), labels.cuda()\n",
    "            pred = model(img_pair)\n",
    "            loss = criterion(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching using prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_and_stitch(model, img1_path, img2_path):\n",
    "    img1 = cv2.resize(cv2.imread(img1_path), (320, 240))\n",
    "    img2 = cv2.resize(cv2.imread(img2_path), (320, 240))\n",
    "\n",
    "    x, y = 100, 60\n",
    "    patch_size = 128\n",
    "    patch_a = img1[y:y+patch_size, x:x+patch_size]\n",
    "    patch_b = img2[y:y+patch_size, x:x+patch_size]\n",
    "\n",
    "    pair = np.concatenate([patch_a, patch_b], axis=2).transpose(2, 0, 1).astype(np.float32) / 255.0\n",
    "    input_tensor = torch.tensor(pair).unsqueeze(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(input_tensor).cpu().numpy().reshape(4, 2)\n",
    "\n",
    "    pts1 = np.float32([[x, y], [x+patch_size, y], [x+patch_size, y+patch_size], [x, y+patch_size]])\n",
    "    pts2 = pts1 + pred\n",
    "    H_pred = cv2.getPerspectiveTransform(pts2, pts1)\n",
    "\n",
    "    # Get corners of img2\n",
    "    h, w = img2.shape[:2]\n",
    "    corners_img2 = np.float32([[0,0], [w,0], [w,h], [0,h]]).reshape(-1,1,2)\n",
    "    warped_corners = cv2.perspectiveTransform(corners_img2, H_pred)\n",
    "\n",
    "    # Combine with img1 corners to determine canvas bounds\n",
    "    all_corners = np.concatenate((warped_corners, np.float32([[0,0], [w,0], [w,h], [0,h]]).reshape(-1,1,2)), axis=0)\n",
    "    [xmin, ymin] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "    translation = [-xmin, -ymin]\n",
    "\n",
    "    H_translation = np.array([[1, 0, translation[0]],\n",
    "                              [0, 1, translation[1]],\n",
    "                              [0, 0, 1]])\n",
    "\n",
    "    warped_img2 = cv2.warpPerspective(img2, H_translation @ H_pred, (xmax - xmin, ymax - ymin))\n",
    "    result = np.zeros_like(warped_img2)\n",
    "    result[translation[1]:img1.shape[0]+translation[1], translation[0]:img1.shape[1]+translation[0]] = img1\n",
    "\n",
    "    mask = (warped_img2 > 0).astype(np.uint8)\n",
    "    stitched = warped_img2.copy()\n",
    "    stitched[mask == 0] = result[mask == 0]\n",
    "\n",
    "    stitched_rgb = cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.title(\"Stitched Image (Full View)\")\n",
    "    plt.imshow(stitched_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img1_path = \"room_2.jpg\"\n",
    "img2_path = \"room_3.jpg\"\n",
    "\n",
    "H = estimate_homography(img1_path, img2_path)\n",
    "dataset = RealHomographyDataset(img1_path, img2_path, H)\n",
    "model = HomographyNet().cuda()\n",
    "train_model(model, dataset)\n",
    "predict_and_stitch(model, img1_path, img2_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
